{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # importuojam duomenis apie irisus (vilkdagius)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 0 0 0 2 2 0 1 1 1 2 0 0 0 0 0 1 0 2 0 0 2 2 1 0 0 2 1 0 2 0 1 1 0 0\n",
      " 2]\n",
      "[1 1 2 0 0 0 2 2 0 1 1 1 2 0 0 0 0 0 1 0 1 0 0 2 2 1 0 0 2 1 0 2 0 1 1 0 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris() # importuojam duomenų rikinį (grazina dictionary, (matricą))\n",
    "\n",
    "X = iris.data #realūs duomenys: 4 parametrai, kuriuos turi gėlė\n",
    "# print(iris.data) # atspausdina informacija\n",
    "# print(X) # sužinom ką reikškia 0 stuplelis\n",
    "Y = iris.target #realūs duomenys\n",
    "# print(Y) # sužinom ką reikškia 1 stuplelis\n",
    "# print(iris.target_names)  # sužinom ką reikškia 2 stuplelis\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y) # train_test_split išmoksta gėlių požymius - grąžinti\n",
    "# print(X_train)\n",
    "# print(X_test)\n",
    "\n",
    "# print(len(Y_train))\n",
    "# print(len(Y_test))\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test) #liepiam suskirstyti duomenis pagal tam tikrus požymius\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n  Mathematical Statistics\" (John Wiley, NY, 1950).\\n- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n  Structure and Classification Rule for Recognition in Partially Exposed\\n  Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n  Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n  on Information Theory, May 1972, 431-433.\\n- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n  conceptual clustering system finds 3 classes in the data.\\n- Many, many more ...\\n\\n|details-end|\\n', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_nuo)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(Y_iki)\n\u001b[1;32m---> 13\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_nuo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n",
      "File \u001b[1;32mc:\\Users\\edita\\Documents\\KURSAI\\240319DMO492DIE\\mokymai\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\edita\\Documents\\KURSAI\\240319DMO492DIE\\mokymai\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\edita\\Documents\\KURSAI\\240319DMO492DIE\\mokymai\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:94\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     96\u001b[0m             type_true, type_pred\n\u001b[0;32m     97\u001b[0m         )\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    101\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "iris = load_iris() # importuojam duomenų rikinį (grazina dictionary, (matricą))\n",
    "print(iris)\n",
    "X_iki = iris.data [:75]#realūs duomenys: 4 parametrai, kuriuos turi gėlė\n",
    "X_nuo = iris.data [75:]\n",
    "Y_iki = iris.data [:75]\n",
    "Y_nuo = iris.data [75:]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(iris.data, iris.target)\n",
    "\n",
    "y_pred = model.predict(X_nuo)\n",
    "print(Y_iki)\n",
    "accuracy = accuracy_score(Y_nuo, y_pred)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[5.1, 3.5, 1.4, 0.2],\n",
    " [4.9, 3.0, 1.4, 0.2],\n",
    " [4.7, 3.2, 1.3, 0.2],\n",
    " [4.6, 3.1, 1.5, 0.2],\n",
    " [5.0, 3.6, 1.4, 0.2],\n",
    " [5.4, 3.9, 1.7, 0.4],\n",
    " [4.6, 3.4, 1.4, 0.3],\n",
    " [5.0, 3.4, 1.5, 0.2],\n",
    " [4.4, 2.9, 1.4, 0.2],\n",
    " [4.9, 3.1, 1.5, 0.1],\n",
    " [6.2, 2.9, 4.3, 1.3],\n",
    " [5.1, 2.5, 3.0, 1.1],\n",
    " [5.7, 2.8, 4.1, 1.3],\n",
    " [6.3, 3.3, 6.0, 2.5],\n",
    " [6.4, 3.2, 5.3, 2.3],\n",
    " [6.3, 2.9, 5.6, 1.8],\n",
    " [6.2, 2.8, 4.8, 1.8],\n",
    " [6.1, 3.0, 4.9, 1.8],\n",
    " [6.4, 2.8, 5.6, 2.1],\n",
    " [6.5, 3.0, 5.8, 2.2]])\n",
    "\n",
    "Y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 2 2]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_chatgpt = np.array([[5.1, 3.5, 1.4, 0.2],\n",
    " [4.9, 3.0, 1.4, 0.2],\n",
    " [4.7, 3.2, 1.3, 0.2],\n",
    " [4.6, 3.1, 1.5, 0.2],\n",
    " [5.0, 3.6, 1.4, 0.2],\n",
    " [5.4, 3.9, 1.7, 0.4],\n",
    " [4.6, 3.4, 1.4, 0.3],\n",
    " [5.0, 3.4, 1.5, 0.2],\n",
    " [4.4, 2.9, 1.4, 0.2],\n",
    " [4.9, 3.1, 1.5, 0.1],\n",
    " [6.2, 2.9, 4.3, 1.3],\n",
    " [5.1, 2.5, 3.0, 1.1],\n",
    " [5.7, 2.8, 4.1, 1.3],\n",
    " [6.3, 3.3, 6.0, 2.5],\n",
    " [6.4, 3.2, 5.3, 2.3],\n",
    " [6.3, 2.9, 5.6, 1.8],\n",
    " [6.2, 2.8, 4.8, 1.8],\n",
    " [6.1, 3.0, 4.9, 1.8],\n",
    " [6.4, 2.8, 5.6, 2.1],\n",
    " [6.5, 3.0, 5.8, 2.2]])\n",
    "\n",
    "Y_chatgpt = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]\n",
    "iris = load_iris()\n",
    "\n",
    "# print(iris)\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_chatgpt)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, Y_chatgpt)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
      "        1.065e+03],\n",
      "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
      "        1.050e+03],\n",
      "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
      "        1.185e+03],\n",
      "       ...,\n",
      "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
      "        8.350e+02],\n",
      "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
      "        8.400e+02],\n",
      "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
      "        5.600e+02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2]), 'frame': None, 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'), 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 178\\n:Number of Attributes: 13 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - Alcohol\\n    - Malic acid\\n    - Ash\\n    - Alcalinity of ash\\n    - Magnesium\\n    - Total phenols\\n    - Flavanoids\\n    - Nonflavanoid phenols\\n    - Proanthocyanins\\n    - Color intensity\\n    - Hue\\n    - OD280/OD315 of diluted wines\\n    - Proline\\n    - class:\\n        - class_0\\n        - class_1\\n        - class_2\\n\\n:Summary Statistics:\\n\\n============================= ==== ===== ======= =====\\n                                Min   Max   Mean     SD\\n============================= ==== ===== ======= =====\\nAlcohol:                      11.0  14.8    13.0   0.8\\nMalic Acid:                   0.74  5.80    2.34  1.12\\nAsh:                          1.36  3.23    2.36  0.27\\nAlcalinity of Ash:            10.6  30.0    19.5   3.3\\nMagnesium:                    70.0 162.0    99.7  14.3\\nTotal Phenols:                0.98  3.88    2.29  0.63\\nFlavanoids:                   0.34  5.08    2.03  1.00\\nNonflavanoid Phenols:         0.13  0.66    0.36  0.12\\nProanthocyanins:              0.41  3.58    1.59  0.57\\nColour Intensity:              1.3  13.0     5.1   2.3\\nHue:                          0.48  1.71    0.96  0.23\\nOD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\nProline:                       278  1680     746   315\\n============================= ==== ===== ======= =====\\n\\n:Missing Attribute Values: None\\n:Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners:\\n\\nForina, M. et al, PARVUS -\\nAn Extendible Package for Data Exploration, Classification and Correlation.\\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n(1) S. Aeberhard, D. Coomans and O. de Vel,\\nComparison of Classifiers in High Dimensional Settings,\\nTech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\\nMathematics and Statistics, James Cook University of North Queensland.\\n(Also submitted to Technometrics).\\n\\nThe data was used with many others for comparing various\\nclassifiers. The classes are separable, though only RDA\\nhas achieved 100% correct classification.\\n(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\\n(All results using the leave-one-out technique)\\n\\n(2) S. Aeberhard, D. Coomans and O. de Vel,\\n\"THE CLASSIFICATION PERFORMANCE OF RDA\"\\nTech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\\nMathematics and Statistics, James Cook University of North Queensland.\\n(Also submitted to Journal of Chemometrics).\\n\\n|details-end|\\n', 'feature_names': ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']}\n",
      "178\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "['class_0' 'class_1' 'class_2']\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(wine\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# suskaidom duomenis X_Train - esami, X_test - testiniai\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X,Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train))\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "print(wine)\n",
    "\n",
    "X = wine.data\n",
    "Y = wine.target\n",
    "print(len(X))\n",
    "print(Y)\n",
    "print(wine.target_names)\n",
    "# print(wine.keys()) # prodo stulpelių pavadinimus\n",
    "print(wine.feature_names)\n",
    "# suskaidom duomenis X_Train - esami, X_test - testiniai\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\n",
    "print(len(X_train))\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, Y_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0\n",
      " 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1\n",
      " 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0\n",
      " 1 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0\n",
      " 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 0\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1\n",
      " 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0]\n",
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1\n",
      " 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1\n",
      " 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 0\n",
      " 1 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0\n",
      " 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 1 0\n",
      " 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0]\n",
      "0.9337231968810916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "b_cancer = load_breast_cancer()\n",
    "\n",
    "X = b_cancer.data\n",
    "Y = b_cancer.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.9, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test) #liepiam suskirstyti (atspėti) duomenis pagal tam tikrus požymius\n",
    "print(y_pred)\n",
    "print(Y_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m Y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m) \u001b[38;5;66;03m#jei nenorim, kad keistųsi)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('divorce.csv', sep=';')\n",
    "df\n",
    "Y = df['Class']\n",
    "X = df.drop('Class', axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42) #jei nenorim, kad keistųsi)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import BaseDecisionTree\n",
    "import pandas as pd \n",
    "df = pd.read_csv('divorce.csv', sep=';')\n",
    "df\n",
    "Y = df['Class']\n",
    "X = df.drop('Class', axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)#jei nenorim, kad keistųsi\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edita\\Documents\\KURSAI\\240319DMO492DIE\\mokymai\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\edita\\Documents\\KURSAI\\240319DMO492DIE\\mokymai\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], X[:,2], clusters)\n",
    "plt.show()\n",
    "\n",
    "X_train, X_test, clusters_train, clusters_test = train_test_split(X, clusters, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, clusters_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, clusters_test)\n",
    "print(accuracy)\n",
    "\n",
    "X_train, X_test, clusters_train, clusters_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, clusters_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, clusters_test)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mokymai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
