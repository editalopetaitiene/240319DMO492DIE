{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import shutil \n",
    "\n",
    "# nurodome kelią į katalogus\n",
    "data_dir = 'is_that_santa'\n",
    "not_santa_dir = os.path.join(data_dir, 'not_santa')\n",
    "santa_dir = os.path.join(data_dir, 'santa')\n",
    "\n",
    "# aprašysim, kokia dalis tenka mokymui, testams ir validacijai\n",
    "splits = (0.7, 0.15, 0.15)\n",
    "\n",
    "def split_data(directory, splits):\n",
    "    \"\"\" \n",
    "    Funkcija yra skirta suskaidyti pateiktam kataloge esančias nuotraukas į tris naujus katalogus, pagal pateiktus išskaidymo dydžius\n",
    "    Parametrai:\n",
    "    directory = nuoroda iki failo kurį norite skaidyti\n",
    "    splits = tuple, su nurodytais kiekiais mokymui, testavimui, validacijai\n",
    "    \"\"\"\n",
    "    images = os.listdir(directory) #gauname visas nuotraukas\n",
    "    random.shuffle(images) #išmaišome nuotraukas, siekiant skirtingu paleidimu metu turėti skirtingus numerius\n",
    "    # print(images)\n",
    "    train_size = int(len(images) * splits[0]) # sužinoma kiekius, kiek nuotraukų reikės mokymams\n",
    "    validation_size = int(len(images) * splits[1])\n",
    "    test_size = int(len(images) * splits[2])\n",
    "    # print(train_size)\n",
    "    # print(validation_size)\n",
    "    # print(test_size)\n",
    "    \n",
    "    # katalogų nuorodų sukūrimas\n",
    "    train_dir = os.path.join(directory, 'train')\n",
    "    validation_dir = os.path.join(directory, 'validation')\n",
    "    test_dir = os.path.join(directory, 'test')\n",
    "\n",
    "    # os.removedirs(train_dir)\n",
    "    # os.removedirs(validation_dir)\n",
    "    # os.removedirs(test_dir)\n",
    "\n",
    "    # TODO: sunaikinti katalogus, prieš tai sunaikinant turinį juose\n",
    "    \n",
    "    # katalogų sukūrimas pagal pateiktas nuorodas\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        if i < train_size:\n",
    "            shutil.copy(os.path.join(directory, image), os.path.join(train_dir, image))\n",
    "        elif i < train_size + validation_size:\n",
    "            shutil.copy(os.path.join(directory, image), os.path.join(validation_dir, image))\n",
    "        else:\n",
    "            shutil.copy(os.path.join(directory, image), os.path.join(test_dir, image))\n",
    "\n",
    "       \n",
    "split_data(not_santa_dir, splits)\n",
    "split_data(santa_dir, splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasiekti nuotraukas\n",
    "# patikrinti ar nuotrauka validi\n",
    "# suvienodinti nuotraukas \n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = 'is_that_santa'\n",
    "not_santa_dir = os.path.join(data_dir, 'not_santa')\n",
    "santa_dir = os.path.join(data_dir, 'santa')\n",
    "\n",
    "# skirta patikrinti ar negausime klaidos, kaip argumentą pateikiame kelią iki nuotraukos\n",
    "def is_valid_image(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:    \n",
    "            img.verify() # patikrina ar nuotrauką galima atidaryti\n",
    "        return True\n",
    "    except (IOError, SyntaxError):\n",
    "        return False\n",
    "    \n",
    "def get_valid_image_files(directory):\n",
    "    \"\"\"\n",
    "    Skirta direktorijoje esančius failus, patikrinti ar jie yra validūs. \n",
    "    Rezultatas - failų pavadinimų sąrašas, su validžių failų pavadinimas\n",
    "    \"\"\"\n",
    "    valid_files = []\n",
    "    # naudojame _, nes neketiname naudoti katalogų train, test ir validation\n",
    "    for root, _, files in os.walk(directory):\n",
    "        if root != directory:\n",
    "        # panaikinti pirma direktorija\n",
    "        # file = files[1:]\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if is_valid_image(file_path):\n",
    "                    valid_files.append(file_path)\n",
    "    return valid_files\n",
    "\n",
    "valid_not_santa_photos = get_valid_image_files(not_santa_dir)\n",
    "valid_santa_photos = get_valid_image_files(santa_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 615 validated image filenames.\n",
      "Found 615 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "# naudojame siekiant sumažinti pixelių vertes iš intervalo 0-255 į intervalą 0-1\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "# kuriame data frame, nes tai yra būdas perteikti informaciją generatoriui\n",
    "not_santa_df = pd.DataFrame({'filename':valid_not_santa_photos})\n",
    "santa_df = pd.DataFrame({'filename':valid_santa_photos})\n",
    "\n",
    "not_santa_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = not_santa_df, #nurodome, kur yra musu nuotrauku sarasas\n",
    "    x_col='filename', #nurodome, kuris stulpelis yra failo kelias musu df\n",
    "    target_size = (150,150), #nurodome nuotraukų dydžius apkerpa, bet nesuspaudžia\n",
    "    batch_size = 20, #nurodome, kiek nuotraukų įdėsime kiekvienos iteracijos metu\n",
    "    class_mode = None) #turime tik du galimus outputus, todėl class mode nustatome none\n",
    "\n",
    "santa_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = santa_df, #nurodome, kur yra musu nuotrauku sarasas\n",
    "    x_col='filename', #nurodome, kuris stulpelis yra failo kelias musu df\n",
    "    target_size = (150,150), #nurodome nuotraukų dydžius\n",
    "    batch_size = 20, #nurodome, kiek nuotraukų įdėsime kiekvienos iteracijos metu\n",
    "    class_mode = None) #turime tik du galimus outputus, todėl class mode nustatome none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "# kuriame šią klase tam, kad turėtume galimybę training matricas pateikti gabalais(batches)\n",
    "class CombinedGenerator(Sequence):\n",
    "    def __init__(self, *generators):\n",
    "        self.generators =generators\n",
    "        self._num_batches = sum(len(gen) for gen in generators)\n",
    "        self.current_generator = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._num_batches\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        for gen in self.generators:\n",
    "            if idx < len(gen):\n",
    "                batch = gen[idx]\n",
    "                # generuojame labels, atsižvelgdami į tai, kiek narių turime savo batche\n",
    "                labels = np.array([0]*batch.shape[0] if gen == not_santa_generator else np.array([1] * batch.shape[0]))\n",
    "                return batch, labels\n",
    "            idx -= len(gen)            \n",
    "    \n",
    "combined_generator = CombinedGenerator(not_santa_generator, santa_generator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edita\\Documents\\KURSAI\\240319DMO492DIE\\mokymai\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential((\n",
    "    layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(150, 150, 3)), #nurodom filtrus ir jų dydžių dimensiją(3,3)\n",
    "    layers.MaxPooling2D(2,2), #sumažinam dimensijas, išlaikant svarbiausias savybes\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'), #antras konvoliucinis sluoksnis\n",
    "    layers.MaxPooling2D((2,2)),  #sumažinam dimensijas, išlaikant svarbiausias savybes\n",
    "    layers.Conv2D(128, (3,3), activation='relu'), \n",
    "    layers.MaxPooling2D((2,2)),  #sumažinam dimensijas, išlaikant svarbiausias savybes\n",
    "    layers.Flatten(), #plokštinam duomenis, paversdami iš 3D į 1D\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid') # išėjimo sluoksnis su vienu neuronu, gražins tikimybę nou 0 iki 1  \n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='binary_crossentropy', #taikome, nes musu klasifikuojami bus 0 arba 1\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edita\\Documents\\KURSAI\\240319DMO492DIE\\mokymai\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 680ms/step - accuracy: 0.4959 - loss: 1.8646\n",
      "Epoch 2/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edita\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 767ms/step - accuracy: 0.4862 - loss: 0.6892\n",
      "Epoch 4/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.8205 - loss: 0.5301\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    combined_generator, # nurodome generatorių, iš kurio duomenis imsime dalimis\n",
    "    steps_per_epoch = len(combined_generator), #pasiims batchu kiekį\n",
    "    epochs = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((150, 150))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array.astype('float32') / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "Santa\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Ne Santa\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Santa\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Santa\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Santa\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    prediction = model.predict(img_array)\n",
    "    return \"Santa\" if prediction[0][0] > 0.5 else 'Ne Santa'\n",
    "\n",
    "print(predict_image('santa1.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('santa2.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('santa3.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('santa4.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('santa5.jpg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mokymai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
