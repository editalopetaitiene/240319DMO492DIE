{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import shutil \n",
    "\n",
    "# nurodome kelią į katalogus\n",
    "data_dir = 'PetImages'\n",
    "cat_dir = os.path.join(data_dir, 'Cat')\n",
    "dog_dir = os.path.join(data_dir, 'Dog')\n",
    "\n",
    "# aprašysim, kokia dalis tenka mokymui, testams ir validacijai\n",
    "splits = (0.7, 0.15, 0.15)\n",
    "\n",
    "def split_data(directory, splits):\n",
    "    \"\"\" \n",
    "    Funkcija yra skirta suskaidyti pateiktam kataloge esančias nuotraukas į tris naujus katalogus, pagal pateiktus išskaidymo dydžius\n",
    "    Parametrai:\n",
    "    directory = nuoroda iki failo kurį norite skaidyti\n",
    "    splits = tuple, su nurodytais kiekiais mokymui, testavimui, validacijai\n",
    "    \"\"\"\n",
    "    images = os.listdir(directory) #gauname visas nuotraukas\n",
    "    random.shuffle(images) #išmaišome nuotraukas, siekiant skirtingu paleidimu metu turėti skirtingus numerius\n",
    "    # print(images)\n",
    "    train_size = int(len(images) * splits[0]) # sužinoma kiekius, kiek nuotraukų reikės mokymams\n",
    "    validation_size = int(len(images) * splits[1])\n",
    "    test_size = int(len(images) * splits[2])\n",
    "    # print(train_size)\n",
    "    # print(validation_size)\n",
    "    # print(test_size)\n",
    "    \n",
    "    # katalogų nuorodų sukūrimas\n",
    "    train_dir = os.path.join(directory, 'train')\n",
    "    validation_dir = os.path.join(directory, 'validation')\n",
    "    test_dir = os.path.join(directory, 'test')\n",
    "\n",
    "    # os.removedirs(train_dir)\n",
    "    # os.removedirs(validation_dir)\n",
    "    # os.removedirs(test_dir)\n",
    "\n",
    "    # TODO: sunaikinti katalogus, prieš tai sunaikinant turinį juose\n",
    "    \n",
    "    # katalogų sukūrimas pagal pateiktas nuorodas\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        if i < train_size:\n",
    "            shutil.copy(os.path.join(directory, image), os.path.join(train_dir, image))\n",
    "        elif i < train_size + validation_size:\n",
    "            shutil.copy(os.path.join(directory, image), os.path.join(validation_dir, image))\n",
    "        else:\n",
    "            shutil.copy(os.path.join(directory, image), os.path.join(test_dir, image))\n",
    "\n",
    "       \n",
    "split_data(cat_dir, splits)\n",
    "split_data(dog_dir, splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edita\\Documents\\KURSAI\\240319DMO492DIE\\mokymai\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "# pasiekti nuotraukas\n",
    "# patikrinti ar nuotrauka validi\n",
    "# suvienodinti nuotraukas \n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = 'PetImages'\n",
    "cat_dir = os.path.join(data_dir, 'Cat')\n",
    "dog_dir = os.path.join(data_dir, 'Dog')\n",
    "\n",
    "# skirta patikrinti ar negausime klaidos, kaip argumentą pateikiame kelią iki nuotraukos\n",
    "def is_valid_image(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:    \n",
    "            img.verify() # patikrina ar nuotrauką galima atidaryti\n",
    "        return True\n",
    "    except (IOError, SyntaxError):\n",
    "        return False\n",
    "    \n",
    "def get_valid_image_files(directory):\n",
    "    \"\"\"\n",
    "    Skirta direktorijoje esančius failus, patikrinti ar jie yra validūs. \n",
    "    Rezultatas - failų pavadinimų sąrašas, su validžių failų pavadinimas\n",
    "    \"\"\"\n",
    "    valid_files = []\n",
    "    # naudojame _, nes neketiname naudoti katalogų train, test ir validation\n",
    "    for root, _, files in os.walk(directory):\n",
    "        if root != directory:\n",
    "        # panaikinti pirma direktorija\n",
    "        # file = files[1:]\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if is_valid_image(file_path):\n",
    "                    valid_files.append(file_path)\n",
    "    return valid_files\n",
    "\n",
    "valid_cat_photos = get_valid_image_files(cat_dir)\n",
    "valid_dog_photos = get_valid_image_files(dog_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499\n",
      "12499\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_cat_photos))\n",
    "print(len(valid_dog_photos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12499 validated image filenames.\n",
      "Found 12499 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "# naudojame siekiant sumažinti pixelių vertes iš intervalo 0-255 į intervalą 0-1\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "# kuriame data frame, nes tai yra būdas perteikti informaciją generatoriui\n",
    "cat_df = pd.DataFrame({'filename':valid_cat_photos})\n",
    "dog_df = pd.DataFrame({'filename':valid_dog_photos})\n",
    "\n",
    "cat_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = cat_df, #nurodome, kur yra musu nuotrauku sarasas\n",
    "    x_col='filename', #nurodome, kuris stulpelis yra failo kelias musu df\n",
    "    target_size = (150,150), #nurodome nuotraukų dydžius apkerpa, bet nesuspaudžia\n",
    "    batch_size = 20, #nurodome, kiek nuotraukų įdėsime kiekvienos iteracijos metu\n",
    "    class_mode = None) #turime tik du galimus outputus, todėl class mode nustatome none\n",
    "\n",
    "dog_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = dog_df, #nurodome, kur yra musu nuotrauku sarasas\n",
    "    x_col='filename', #nurodome, kuris stulpelis yra failo kelias musu df\n",
    "    target_size = (150,150), #nurodome nuotraukų dydžius\n",
    "    batch_size = 20, #nurodome, kiek nuotraukų įdėsime kiekvienos iteracijos metu\n",
    "    class_mode = None) #turime tik du galimus outputus, todėl class mode nustatome none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "# kuriame šią klase tam, kad turėtume galimybę training matricas pateikti gabalais(batches)\n",
    "class CombinedGenerator(Sequence):\n",
    "    def __init__(self, *generators):\n",
    "        self.generators =generators\n",
    "        self._num_batches = sum(len(gen) for gen in generators)\n",
    "        self.current_generator = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._num_batches\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        for gen in self.generators:\n",
    "            if idx < len(gen):\n",
    "                batch = gen[idx]\n",
    "                # generuojame labels, atsižvelgdami į tai, kiek narių turime savo batche\n",
    "                labels = np.array([0]*batch.shape[0] if gen == cat_generator else np.array([1] * batch.shape[0]))\n",
    "                return batch, labels\n",
    "            idx -= len(gen)            \n",
    "    \n",
    "combined_generator = CombinedGenerator(cat_generator, dog_generator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential((\n",
    "    layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(150, 150, 3)), #nurodom filtrus ir jų dydžių dimensiją(3,3)\n",
    "    layers.MaxPooling2D(2,2), #sumažinam dimensijas, išlaikant svarbiausias savybes\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'), #antras konvoliucinis sluoksnis\n",
    "    layers.MaxPooling2D((2,2)),  #sumažinam dimensijas, išlaikant svarbiausias savybes\n",
    "    layers.Conv2D(128, (3,3), activation='relu'), \n",
    "    layers.MaxPooling2D((2,2)),  #sumažinam dimensijas, išlaikant svarbiausias savybes\n",
    "    layers.Flatten(), #plokštinam duomenis, paversdami iš 3D į 1D\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid') # išėjimo sluoksnis su vienu neuronu, gražins tikimybę nou 0 iki 1  \n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam', \n",
    "    loss='binary_crossentropy', #taikome, nes musu klasifikuojami bus 0 arba 1\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 149/1250\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:48\u001b[0m 589ms/step - accuracy: 0.6791 - loss: 0.6003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edita\\Documents\\KURSAI\\240319DMO492DIE\\mokymai\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 548ms/step - accuracy: 0.6761 - loss: 0.6066\n",
      "Epoch 2/5\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edita\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 612ms/step - accuracy: 0.7573 - loss: 0.4993\n",
      "Epoch 4/5\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 638ms/step - accuracy: 0.7943 - loss: 0.4410\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    combined_generator, # nurodome generatorių, iš kurio duomenis imsime dalimis\n",
    "    steps_per_epoch = len(combined_generator), #pasiims batchu kiekį\n",
    "    epochs = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((150, 150))\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array.astype('float32') / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Kate\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Kate\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Suo\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Kate\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Suo\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Suo\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Suo\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Suo\n",
      "--------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Suo\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    prediction = model.predict(img_array)\n",
    "    return \"Suo\" if prediction[0][0] > 0.5 else 'Kate'\n",
    "\n",
    "print(predict_image('kate.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('kate2.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('kate3.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('kate4.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('Suo.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('Suo2.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('Suo3.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('Suo4.jpg'))\n",
    "print('--------------')\n",
    "print(predict_image('Suo5.jpg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mokymai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
